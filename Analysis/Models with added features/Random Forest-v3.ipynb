{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acer\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\compat\\_optional.py:138: UserWarning: Pandas requires version '2.7.0' or newer of 'numexpr' (version '2.6.9' currently installed).\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# Import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report,confusion_matrix, ConfusionMatrixDisplay, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>prop_unique_words</th>\n",
       "      <th>avg_sentence_length</th>\n",
       "      <th>prop_punctuations</th>\n",
       "      <th>prop_stopwords</th>\n",
       "      <th>prop_words_in_quotes</th>\n",
       "      <th>prop_nouns</th>\n",
       "      <th>prop_verbs</th>\n",
       "      <th>prop_adjectives</th>\n",
       "      <th>prop_discourse_relations</th>\n",
       "      <th>textblob_sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>class_label</th>\n",
       "      <th>text_preprocessed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20912</th>\n",
       "      <td>20912</td>\n",
       "      <td>0.229954</td>\n",
       "      <td>0.181304</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.583429</td>\n",
       "      <td>0.515881</td>\n",
       "      <td>0.332684</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.649008</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.675265</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>The Arrivals Bosanski Prijevod 36-theStoryOfJe...</td>\n",
       "      <td>1</td>\n",
       "      <td>arriv bosanski prijevod 36thestoryofjesussuppo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11644</th>\n",
       "      <td>11644</td>\n",
       "      <td>0.539677</td>\n",
       "      <td>0.541733</td>\n",
       "      <td>0.356333</td>\n",
       "      <td>0.469383</td>\n",
       "      <td>0.632330</td>\n",
       "      <td>0.362808</td>\n",
       "      <td>0.833539</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.501173</td>\n",
       "      <td>0.535221</td>\n",
       "      <td>0.518292</td>\n",
       "      <td>0.322086</td>\n",
       "      <td>0.502741</td>\n",
       "      <td>Half of Germans want new elections after coali...</td>\n",
       "      <td>0</td>\n",
       "      <td>half german want new elect coalit talk fail be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15508</th>\n",
       "      <td>15508</td>\n",
       "      <td>0.566192</td>\n",
       "      <td>0.566374</td>\n",
       "      <td>0.422957</td>\n",
       "      <td>0.512227</td>\n",
       "      <td>0.597302</td>\n",
       "      <td>0.317863</td>\n",
       "      <td>0.826211</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.530938</td>\n",
       "      <td>0.658307</td>\n",
       "      <td>0.474156</td>\n",
       "      <td>0.204380</td>\n",
       "      <td>0.503698</td>\n",
       "      <td>Paul Ryan: Failure of Obamacare Replacement Ma...</td>\n",
       "      <td>0</td>\n",
       "      <td>paul ryan failur obamacar replac make tax refo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12020</th>\n",
       "      <td>12020</td>\n",
       "      <td>0.551511</td>\n",
       "      <td>0.553166</td>\n",
       "      <td>0.401542</td>\n",
       "      <td>0.510845</td>\n",
       "      <td>0.601535</td>\n",
       "      <td>0.344543</td>\n",
       "      <td>0.820188</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.505343</td>\n",
       "      <td>0.570749</td>\n",
       "      <td>0.579872</td>\n",
       "      <td>0.289256</td>\n",
       "      <td>0.491288</td>\n",
       "      <td>Having nuclear weapons 'matter of life and dea...</td>\n",
       "      <td>0</td>\n",
       "      <td>nuclear weapon matter life death north korea a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28157</th>\n",
       "      <td>28157</td>\n",
       "      <td>0.530959</td>\n",
       "      <td>0.524410</td>\n",
       "      <td>0.429420</td>\n",
       "      <td>0.636065</td>\n",
       "      <td>0.534970</td>\n",
       "      <td>0.391446</td>\n",
       "      <td>0.836109</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.520611</td>\n",
       "      <td>0.639611</td>\n",
       "      <td>0.556508</td>\n",
       "      <td>0.227437</td>\n",
       "      <td>0.536869</td>\n",
       "      <td>Republican presidential candidate Cruz propose...</td>\n",
       "      <td>0</td>\n",
       "      <td>republican presidenti candid cruz propos milit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  char_count  word_count  sentence_count  prop_unique_words  \\\n",
       "20912       20912    0.229954    0.181304        0.000000           0.583429   \n",
       "11644       11644    0.539677    0.541733        0.356333           0.469383   \n",
       "15508       15508    0.566192    0.566374        0.422957           0.512227   \n",
       "12020       12020    0.551511    0.553166        0.401542           0.510845   \n",
       "28157       28157    0.530959    0.524410        0.429420           0.636065   \n",
       "\n",
       "       avg_sentence_length  prop_punctuations  prop_stopwords  \\\n",
       "20912             0.515881           0.332684        1.000000   \n",
       "11644             0.632330           0.362808        0.833539   \n",
       "15508             0.597302           0.317863        0.826211   \n",
       "12020             0.601535           0.344543        0.820188   \n",
       "28157             0.534970           0.391446        0.836109   \n",
       "\n",
       "       prop_words_in_quotes  prop_nouns  prop_verbs  prop_adjectives  \\\n",
       "20912                   1.0    0.649008    1.000000         0.675265   \n",
       "11644                   1.0    0.501173    0.535221         0.518292   \n",
       "15508                   1.0    0.530938    0.658307         0.474156   \n",
       "12020                   1.0    0.505343    0.570749         0.579872   \n",
       "28157                   1.0    0.520611    0.639611         0.556508   \n",
       "\n",
       "       prop_discourse_relations  textblob_sentiment  \\\n",
       "20912                  0.000000            0.500000   \n",
       "11644                  0.322086            0.502741   \n",
       "15508                  0.204380            0.503698   \n",
       "12020                  0.289256            0.491288   \n",
       "28157                  0.227437            0.536869   \n",
       "\n",
       "                                                    text  class_label  \\\n",
       "20912  The Arrivals Bosanski Prijevod 36-theStoryOfJe...            1   \n",
       "11644  Half of Germans want new elections after coali...            0   \n",
       "15508  Paul Ryan: Failure of Obamacare Replacement Ma...            0   \n",
       "12020  Having nuclear weapons 'matter of life and dea...            0   \n",
       "28157  Republican presidential candidate Cruz propose...            0   \n",
       "\n",
       "                                       text_preprocessed  \n",
       "20912  arriv bosanski prijevod 36thestoryofjesussuppo...  \n",
       "11644  half german want new elect coalit talk fail be...  \n",
       "15508  paul ryan failur obamacar replac make tax refo...  \n",
       "12020  nuclear weapon matter life death north korea a...  \n",
       "28157  republican presidenti candid cruz propos milit...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv(\"../../Data/Final datasets/train_data.csv\")\n",
    "val_data = pd.read_csv(\"../../Data/Final datasets/val_data.csv\")\n",
    "test_data = pd.read_csv(\"../../Data/Final datasets/test_data.csv\")\n",
    "\n",
    "train_data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_text = train_data[\"text_preprocessed\"].values\n",
    "y_train = train_data[\"class_label\"].values\n",
    "\n",
    "X_val_text = val_data[\"text_preprocessed\"].values\n",
    "y_val = val_data[\"class_label\"].values\n",
    "\n",
    "X_test_text = test_data[\"text_preprocessed\"].values\n",
    "y_test = test_data[\"class_label\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model (Random Forest)\n",
    "## Using CountVectoriser with Bag of Words, Unigrams + Bigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using 134 and 3k features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with 134 features\n",
    "vectorizer = CountVectorizer(stop_words='english', ngram_range=(1,2), min_df=0.15)\n",
    "vectorizer.fit(X_train_text)\n",
    "\n",
    "X_train = vectorizer.transform(X_train_text)\n",
    "X_val = vectorizer.transform(X_val_text)\n",
    "X_test = vectorizer.transform(X_test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of features used: 134\n"
     ]
    }
   ],
   "source": [
    "print(\"number of features used:\", len(vectorizer.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialise Decision Tree\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=0) \n",
    "\n",
    "# train model\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_pred = clf.predict(X_val)\n",
    "print(classification_report(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  with 3k features\n",
    "vectorizer = CountVectorizer(stop_words='english', ngram_range=(1,2), min_df=0.01)\n",
    "vectorizer.fit(X_train_text)\n",
    "\n",
    "X_train = vectorizer.transform(X_train_text)\n",
    "X_val = vectorizer.transform(X_val_text)\n",
    "X_test = vectorizer.transform(X_test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_pred = clf.predict(X_val)\n",
    "print(classification_report(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using 134 and 3k with all added features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with 134 features\n",
    "vectorizer = CountVectorizer(stop_words='english', ngram_range=(1,2), min_df=0.15)\n",
    "vectorizer.fit(X_train_text)\n",
    "\n",
    "X_train = vectorizer.transform(X_train_text)\n",
    "X_val = vectorizer.transform(X_val_text)\n",
    "X_test = vectorizer.transform(X_test_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Tf-ldf\n",
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with unigram and bigram\n",
      "Testing using validation data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.90      0.93      6361\n",
      "           1       0.91      0.96      0.94      6659\n",
      "\n",
      "    accuracy                           0.93     13020\n",
      "   macro avg       0.93      0.93      0.93     13020\n",
      "weighted avg       0.93      0.93      0.93     13020\n",
      "\n",
      "------------------------------------------\n",
      "Testing using test data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.91      0.94      6361\n",
      "           1       0.92      0.96      0.94      6660\n",
      "\n",
      "    accuracy                           0.94     13021\n",
      "   macro avg       0.94      0.94      0.94     13021\n",
      "weighted avg       0.94      0.94      0.94     13021\n",
      "\n",
      "------------------------------------------\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# with 134 features\n",
    "tfidf_params = {'unigram and bigram': (1,2)}\n",
    "\n",
    "for ngram, values in tfidf_params.items():\n",
    "    tfidf_vectorizer = TfidfVectorizer(analyzer='word', stop_words='english', ngram_range=values, min_df=0.15)\n",
    "    tfidf_vectorizer.fit(X_train_text)\n",
    "\n",
    "    X_train = tfidf_vectorizer.transform(X_train_text)\n",
    "    X_val = tfidf_vectorizer.transform(X_val_text)\n",
    "    X_test = tfidf_vectorizer.transform(X_test_text)\n",
    "\n",
    "    print(f\"Model with {ngram}\")\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Validation Data\n",
    "    print(\"Testing using validation data:\")    \n",
    "    y_val_pred = clf.predict(X_val)\n",
    "    print(classification_report(y_val, y_val_pred))\n",
    "    print(\"------------------------------------------\")\n",
    "\n",
    "    # Test Data\n",
    "    print(\"Testing using test data:\")  \n",
    "    y_test_pred = clf.predict(X_test)\n",
    "    print(classification_report(y_test, y_test_pred))\n",
    "    print(\"------------------------------------------\")\n",
    "    print(\"------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with unigram and bigram\n",
      "Testing using validation data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.96      6361\n",
      "           1       0.95      0.97      0.96      6659\n",
      "\n",
      "    accuracy                           0.96     13020\n",
      "   macro avg       0.96      0.96      0.96     13020\n",
      "weighted avg       0.96      0.96      0.96     13020\n",
      "\n",
      "------------------------------------------\n",
      "Testing using test data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96      6361\n",
      "           1       0.95      0.97      0.96      6660\n",
      "\n",
      "    accuracy                           0.96     13021\n",
      "   macro avg       0.96      0.96      0.96     13021\n",
      "weighted avg       0.96      0.96      0.96     13021\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tfidf_params = {'unigram and bigram': (1,2)}\n",
    "\n",
    "for ngram, values in tfidf_params.items():\n",
    "    tfidf_vectorizer = TfidfVectorizer(analyzer='word', stop_words='english', ngram_range=values, min_df=0.01)\n",
    "    tfidf_vectorizer.fit(X_train_text)\n",
    "\n",
    "    X_train = tfidf_vectorizer.transform(X_train_text)\n",
    "    X_val = tfidf_vectorizer.transform(X_val_text)\n",
    "    X_test = tfidf_vectorizer.transform(X_test_text)\n",
    "\n",
    "    print(f\"Model with {ngram}\")\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Validation Data\n",
    "    print(\"Testing using validation data:\")    \n",
    "    y_val_pred = clf.predict(X_val)\n",
    "    print(classification_report(y_val, y_val_pred))\n",
    "    print(\"------------------------------------------\")\n",
    "\n",
    "    # Test Data\n",
    "    print(\"Testing using test data:\")\n",
    "    y_test_pred = clf.predict(X_test)\n",
    "    print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection with all added features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_added_features_scaled = pd.read_csv(\"../../Data/Final datasets/train_data.csv\")\n",
    "# val_data_added_features_scaled = pd.read_csv(\"../../Data/Final datasets/val_data.csv\")\n",
    "test_data_added_features_scaled = pd.read_csv(\"../../Data/Final datasets/test_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_data_added_features_scaled[\"class_label\"].values\n",
    "y_test = test_data_added_features_scaled[\"class_label\"].values\n",
    "# y_val = val_data_features[\"class_label\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing using test data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.90      0.93      6361\n",
      "           1       0.91      0.97      0.94      6660\n",
      "\n",
      "    accuracy                           0.94     13021\n",
      "   macro avg       0.94      0.93      0.94     13021\n",
      "weighted avg       0.94      0.94      0.94     13021\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# with 134 features\n",
    "tfidf_vectorizer = TfidfVectorizer(analyzer='word', stop_words='english', ngram_range=(1,2), min_df=0.15)\n",
    "\n",
    "# Create mapper object to combine added features and tfidf word vectors\n",
    "mapper = DataFrameMapper([\n",
    "    (['char_count', 'word_count', 'sentence_count', 'prop_unique_words',\n",
    "    'avg_sentence_length', 'prop_punctuations', 'prop_stopwords',\n",
    "    'prop_words_in_quotes', 'prop_nouns', 'prop_verbs', 'prop_adjectives',\n",
    "    'prop_discourse_relations', 'textblob_sentiment'], None), \n",
    "    ('text_preprocessed', tfidf_vectorizer)\n",
    "])\n",
    "\n",
    "X_train_added_features = mapper.fit_transform(train_data_added_features_scaled)\n",
    "X_test_added_features = mapper.transform(test_data_added_features_scaled)\n",
    "\n",
    "clf.fit(X_train_added_features, y_train)\n",
    "\n",
    "# Test Data\n",
    "print(\"Testing using test data:\")\n",
    "y_test_pred = clf.predict(X_test_added_features)\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing using test data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      6361\n",
      "           1       0.95      0.98      0.96      6660\n",
      "\n",
      "    accuracy                           0.96     13021\n",
      "   macro avg       0.96      0.96      0.96     13021\n",
      "weighted avg       0.96      0.96      0.96     13021\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# with 3k features\n",
    "tfidf_vectorizer = TfidfVectorizer(analyzer='word', stop_words='english', ngram_range=(1,2), min_df=0.01)\n",
    "\n",
    "# Create mapper object to combine added features and tfidf word vectors\n",
    "mapper = DataFrameMapper([\n",
    "    (['char_count', 'word_count', 'sentence_count', 'prop_unique_words',\n",
    "    'avg_sentence_length', 'prop_punctuations', 'prop_stopwords',\n",
    "    'prop_words_in_quotes', 'prop_nouns', 'prop_verbs', 'prop_adjectives',\n",
    "    'prop_discourse_relations', 'textblob_sentiment'], None), \n",
    "    ('text_preprocessed', tfidf_vectorizer)\n",
    "])\n",
    "\n",
    "X_train_added_features = mapper.fit_transform(train_data_added_features_scaled)\n",
    "X_test_added_features = mapper.transform(test_data_added_features_scaled)\n",
    "\n",
    "clf.fit(X_train_added_features, y_train)\n",
    "\n",
    "# Test Data\n",
    "print(\"Testing using test data:\")\n",
    "y_test_pred = clf.predict(X_test_added_features)\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection with selected added features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing using test data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.90      0.93      6361\n",
      "           1       0.91      0.97      0.94      6660\n",
      "\n",
      "    accuracy                           0.94     13021\n",
      "   macro avg       0.94      0.93      0.93     13021\n",
      "weighted avg       0.94      0.94      0.93     13021\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# with 134 features\n",
    "tfidf_vectorizer = TfidfVectorizer(analyzer='word', stop_words='english', ngram_range=(1,2), min_df=0.15)\n",
    "\n",
    "# Create mapper object to combine added features and tfidf word vectors\n",
    "mapper = DataFrameMapper([\n",
    "    (['char_count', 'word_count', 'prop_unique_words', 'avg_sentence_length', 'prop_punctuations', 'prop_stopwords', 'prop_nouns'], None), \n",
    "    ('text_preprocessed', tfidf_vectorizer)\n",
    "])\n",
    "\n",
    "X_train_added_features = mapper.fit_transform(train_data_added_features_scaled)\n",
    "X_test_added_features = mapper.transform(test_data_added_features_scaled)\n",
    "\n",
    "clf.fit(X_train_added_features, y_train)\n",
    "\n",
    "# Test Data\n",
    "print(\"Testing using test data:\")\n",
    "y_test_pred = clf.predict(X_test_added_features)\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing using test data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.96      6361\n",
      "           1       0.95      0.98      0.96      6660\n",
      "\n",
      "    accuracy                           0.96     13021\n",
      "   macro avg       0.96      0.96      0.96     13021\n",
      "weighted avg       0.96      0.96      0.96     13021\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# with 3k features\n",
    "tfidf_vectorizer = TfidfVectorizer(analyzer='word', stop_words='english', ngram_range=(1,2), min_df=0.01)\n",
    "\n",
    "# Create mapper object to combine added features and tfidf word vectors\n",
    "mapper = DataFrameMapper([\n",
    "    (['char_count', 'word_count', 'prop_unique_words', 'avg_sentence_length', 'prop_punctuations', 'prop_stopwords', 'prop_nouns'], None), \n",
    "    ('text_preprocessed', tfidf_vectorizer)\n",
    "])\n",
    "\n",
    "X_train_added_features = mapper.fit_transform(train_data_added_features_scaled)\n",
    "X_test_added_features = mapper.transform(test_data_added_features_scaled)\n",
    "\n",
    "clf.fit(X_train_added_features, y_train)\n",
    "\n",
    "# Test Data\n",
    "print(\"Testing using test data:\")\n",
    "y_test_pred = clf.predict(X_test_added_features)\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
