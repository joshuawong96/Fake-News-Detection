{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acer\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\compat\\_optional.py:138: UserWarning: Pandas requires version '2.7.0' or newer of 'numexpr' (version '2.6.9' currently installed).\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# Import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report,confusion_matrix, ConfusionMatrixDisplay, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>prop_unique_words</th>\n",
       "      <th>avg_sentence_length</th>\n",
       "      <th>prop_punctuations</th>\n",
       "      <th>prop_stopwords</th>\n",
       "      <th>prop_words_in_quotes</th>\n",
       "      <th>prop_nouns</th>\n",
       "      <th>prop_verbs</th>\n",
       "      <th>prop_adjectives</th>\n",
       "      <th>prop_discourse_relations</th>\n",
       "      <th>textblob_sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>class_label</th>\n",
       "      <th>text_preprocessed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23127</th>\n",
       "      <td>23127</td>\n",
       "      <td>0.432298</td>\n",
       "      <td>0.436326</td>\n",
       "      <td>0.305247</td>\n",
       "      <td>0.630767</td>\n",
       "      <td>0.544238</td>\n",
       "      <td>0.387116</td>\n",
       "      <td>0.820188</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.567131</td>\n",
       "      <td>0.556564</td>\n",
       "      <td>0.427766</td>\n",
       "      <td>0.115702</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>Tillerson says 'no disagreement' between Trump...</td>\n",
       "      <td>0</td>\n",
       "      <td>tillerson say disagr trump xi north korea beij...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28025</th>\n",
       "      <td>28025</td>\n",
       "      <td>0.509897</td>\n",
       "      <td>0.508718</td>\n",
       "      <td>0.345213</td>\n",
       "      <td>0.544648</td>\n",
       "      <td>0.599773</td>\n",
       "      <td>0.315367</td>\n",
       "      <td>0.809549</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.510272</td>\n",
       "      <td>0.656680</td>\n",
       "      <td>0.554072</td>\n",
       "      <td>0.058577</td>\n",
       "      <td>0.468611</td>\n",
       "      <td>Israeli missiles target Syrian military facili...</td>\n",
       "      <td>0</td>\n",
       "      <td>isra missil target syrian militari facil near ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11775</th>\n",
       "      <td>11775</td>\n",
       "      <td>0.512037</td>\n",
       "      <td>0.518083</td>\n",
       "      <td>0.393601</td>\n",
       "      <td>0.534750</td>\n",
       "      <td>0.562996</td>\n",
       "      <td>0.331723</td>\n",
       "      <td>0.876460</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.497188</td>\n",
       "      <td>0.664309</td>\n",
       "      <td>0.442732</td>\n",
       "      <td>0.268199</td>\n",
       "      <td>0.545048</td>\n",
       "      <td>Ivanka Trump Surprised by ‘Level of Viciousnes...</td>\n",
       "      <td>0</td>\n",
       "      <td>ivanka trump surpris level vicious washington ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21143</th>\n",
       "      <td>21143</td>\n",
       "      <td>0.440247</td>\n",
       "      <td>0.436326</td>\n",
       "      <td>0.288884</td>\n",
       "      <td>0.640234</td>\n",
       "      <td>0.560882</td>\n",
       "      <td>0.392433</td>\n",
       "      <td>0.831936</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.501511</td>\n",
       "      <td>0.584018</td>\n",
       "      <td>0.525072</td>\n",
       "      <td>0.289256</td>\n",
       "      <td>0.508214</td>\n",
       "      <td>U.S.-led anti-Islamic State coalition says Ira...</td>\n",
       "      <td>0</td>\n",
       "      <td>usl antiislam state coalit say iraqikurdish cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15979</th>\n",
       "      <td>15979</td>\n",
       "      <td>0.639049</td>\n",
       "      <td>0.629775</td>\n",
       "      <td>0.497837</td>\n",
       "      <td>0.507067</td>\n",
       "      <td>0.605376</td>\n",
       "      <td>0.373144</td>\n",
       "      <td>0.818458</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.579655</td>\n",
       "      <td>0.624310</td>\n",
       "      <td>0.510125</td>\n",
       "      <td>0.197051</td>\n",
       "      <td>0.516107</td>\n",
       "      <td>Crooked Hillary Campaign Chairman John Podesta...</td>\n",
       "      <td>1</td>\n",
       "      <td>crook hillari campaign chairman john podesta t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  char_count  word_count  sentence_count  prop_unique_words  \\\n",
       "23127       23127    0.432298    0.436326        0.305247           0.630767   \n",
       "28025       28025    0.509897    0.508718        0.345213           0.544648   \n",
       "11775       11775    0.512037    0.518083        0.393601           0.534750   \n",
       "21143       21143    0.440247    0.436326        0.288884           0.640234   \n",
       "15979       15979    0.639049    0.629775        0.497837           0.507067   \n",
       "\n",
       "       avg_sentence_length  prop_punctuations  prop_stopwords  \\\n",
       "23127             0.544238           0.387116        0.820188   \n",
       "28025             0.599773           0.315367        0.809549   \n",
       "11775             0.562996           0.331723        0.876460   \n",
       "21143             0.560882           0.392433        0.831936   \n",
       "15979             0.605376           0.373144        0.818458   \n",
       "\n",
       "       prop_words_in_quotes  prop_nouns  prop_verbs  prop_adjectives  \\\n",
       "23127                   1.0    0.567131    0.556564         0.427766   \n",
       "28025                   1.0    0.510272    0.656680         0.554072   \n",
       "11775                   1.0    0.497188    0.664309         0.442732   \n",
       "21143                   1.0    0.501511    0.584018         0.525072   \n",
       "15979                   1.0    0.579655    0.624310         0.510125   \n",
       "\n",
       "       prop_discourse_relations  textblob_sentiment  \\\n",
       "23127                  0.115702            0.566667   \n",
       "28025                  0.058577            0.468611   \n",
       "11775                  0.268199            0.545048   \n",
       "21143                  0.289256            0.508214   \n",
       "15979                  0.197051            0.516107   \n",
       "\n",
       "                                                    text  class_label  \\\n",
       "23127  Tillerson says 'no disagreement' between Trump...            0   \n",
       "28025  Israeli missiles target Syrian military facili...            0   \n",
       "11775  Ivanka Trump Surprised by ‘Level of Viciousnes...            0   \n",
       "21143  U.S.-led anti-Islamic State coalition says Ira...            0   \n",
       "15979  Crooked Hillary Campaign Chairman John Podesta...            1   \n",
       "\n",
       "                                       text_preprocessed  \n",
       "23127  tillerson say disagr trump xi north korea beij...  \n",
       "28025  isra missil target syrian militari facil near ...  \n",
       "11775  ivanka trump surpris level vicious washington ...  \n",
       "21143  usl antiislam state coalit say iraqikurdish cl...  \n",
       "15979  crook hillari campaign chairman john podesta t...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv(\"../../Data/Final datasets/train_data.csv\")\n",
    "val_data = pd.read_csv(\"../../Data/Final datasets/val_data.csv\")\n",
    "test_data = pd.read_csv(\"../../Data/Final datasets/test_data.csv\")\n",
    "\n",
    "train_data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_text = train_data[\"text_preprocessed\"].values\n",
    "y_train = train_data[\"class_label\"].values\n",
    "\n",
    "X_val_text = val_data[\"text_preprocessed\"].values\n",
    "y_val = val_data[\"class_label\"].values\n",
    "\n",
    "X_test_text = test_data[\"text_preprocessed\"].values\n",
    "y_test = test_data[\"class_label\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model (Decision Tree)\n",
    "## Using CountVectoriser with Bag of Words, Unigrams + Bigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using 134 and 3k features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with 134 features\n",
    "vectorizer = CountVectorizer(stop_words='english', ngram_range=(1,2), min_df=0.15)\n",
    "vectorizer.fit(X_train_text)\n",
    "\n",
    "X_train = vectorizer.transform(X_train_text)\n",
    "X_val = vectorizer.transform(X_val_text)\n",
    "X_test = vectorizer.transform(X_test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of features used: 134\n"
     ]
    }
   ],
   "source": [
    "print(\"number of features used:\", len(vectorizer.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(random_state=0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialise Decision Tree\n",
    "clf = DecisionTreeClassifier(criterion='gini', random_state=0) \n",
    "\n",
    "# train model\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.89      0.90      6361\n",
      "           1       0.90      0.91      0.90      6659\n",
      "\n",
      "    accuracy                           0.90     13020\n",
      "   macro avg       0.90      0.90      0.90     13020\n",
      "weighted avg       0.90      0.90      0.90     13020\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_val_pred = clf.predict(X_val)\n",
    "print(classification_report(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.90      0.90      6361\n",
      "           1       0.91      0.91      0.91      6660\n",
      "\n",
      "    accuracy                           0.91     13021\n",
      "   macro avg       0.91      0.91      0.91     13021\n",
      "weighted avg       0.91      0.91      0.91     13021\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.tree import export_graphviz\n",
    "# import pydotplus\n",
    "# from six import StringIO  \n",
    "# from IPython.display import Image\n",
    "\n",
    "# feature_cols = ['text_preprocessed']\n",
    "\n",
    "# dot_data = StringIO()\n",
    "# export_graphviz(clf, out_file = dot_data, \n",
    "#                       feature_names = feature_cols,  \n",
    "#                      filled = True, rounded = True,  \n",
    "#                     special_characters = True)\n",
    "\n",
    "# graph = pydotplus.graph_from_dot_data(dot_data.getvalue())\n",
    "# Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.tree import plot_tree\n",
    "\n",
    "# plot_tree(clf.fit(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  with 3k features\n",
    "vectorizer = CountVectorizer(stop_words='english', ngram_range=(1,2), min_df=0.01)\n",
    "vectorizer.fit(X_train_text)\n",
    "\n",
    "X_train = vectorizer.transform(X_train_text)\n",
    "X_val = vectorizer.transform(X_val_text)\n",
    "X_test = vectorizer.transform(X_test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_pred = clf.predict(X_val)\n",
    "print(classification_report(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using 134 and 3k with all added features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with 134 features\n",
    "vectorizer = CountVectorizer(stop_words='english', ngram_range=(1,2), min_df=0.15)\n",
    "vectorizer.fit(X_train_text)\n",
    "\n",
    "X_train = vectorizer.transform(X_train_text)\n",
    "X_val = vectorizer.transform(X_val_text)\n",
    "X_test = vectorizer.transform(X_test_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Tf-ldf\n",
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with unigram and bigram\n",
      "Testing using validation data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.89      0.90      6361\n",
      "           1       0.90      0.91      0.91      6659\n",
      "\n",
      "    accuracy                           0.90     13020\n",
      "   macro avg       0.90      0.90      0.90     13020\n",
      "weighted avg       0.90      0.90      0.90     13020\n",
      "\n",
      "------------------------------------------\n",
      "Testing using test data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.90      0.91      6361\n",
      "           1       0.91      0.92      0.91      6660\n",
      "\n",
      "    accuracy                           0.91     13021\n",
      "   macro avg       0.91      0.91      0.91     13021\n",
      "weighted avg       0.91      0.91      0.91     13021\n",
      "\n",
      "------------------------------------------\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# with 134 features\n",
    "tfidf_params = {'unigram and bigram': (1,2)}\n",
    "\n",
    "for ngram, values in tfidf_params.items():\n",
    "    tfidf_vectorizer = TfidfVectorizer(analyzer='word', stop_words='english', ngram_range=values, min_df=0.15)\n",
    "    tfidf_vectorizer.fit(X_train_text)\n",
    "\n",
    "    X_train = tfidf_vectorizer.transform(X_train_text)\n",
    "    X_val = tfidf_vectorizer.transform(X_val_text)\n",
    "    X_test = tfidf_vectorizer.transform(X_test_text)\n",
    "\n",
    "    print(f\"Model with {ngram}\")\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Validation Data\n",
    "    print(\"Testing using validation data:\")    \n",
    "    y_val_pred = clf.predict(X_val)\n",
    "    print(classification_report(y_val, y_val_pred))\n",
    "    print(\"------------------------------------------\")\n",
    "\n",
    "    # Test Data\n",
    "    print(\"Testing using test data:\")  \n",
    "    y_test_pred = clf.predict(X_test)\n",
    "    print(classification_report(y_test, y_test_pred))\n",
    "    print(\"------------------------------------------\")\n",
    "    print(\"------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with unigram and bigram\n",
      "Testing using validation data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.95      6361\n",
      "           1       0.94      0.95      0.95      6659\n",
      "\n",
      "    accuracy                           0.95     13020\n",
      "   macro avg       0.95      0.95      0.95     13020\n",
      "weighted avg       0.95      0.95      0.95     13020\n",
      "\n",
      "------------------------------------------\n",
      "Testing using test data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94      6361\n",
      "           1       0.94      0.95      0.95      6660\n",
      "\n",
      "    accuracy                           0.94     13021\n",
      "   macro avg       0.94      0.94      0.94     13021\n",
      "weighted avg       0.94      0.94      0.94     13021\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tfidf_params = {'unigram and bigram': (1,2)}\n",
    "\n",
    "for ngram, values in tfidf_params.items():\n",
    "    tfidf_vectorizer = TfidfVectorizer(analyzer='word', stop_words='english', ngram_range=values, min_df=0.01)\n",
    "    tfidf_vectorizer.fit(X_train_text)\n",
    "\n",
    "    X_train = tfidf_vectorizer.transform(X_train_text)\n",
    "    X_val = tfidf_vectorizer.transform(X_val_text)\n",
    "    X_test = tfidf_vectorizer.transform(X_test_text)\n",
    "\n",
    "    print(f\"Model with {ngram}\")\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Validation Data\n",
    "    print(\"Testing using validation data:\")    \n",
    "    y_val_pred = clf.predict(X_val)\n",
    "    print(classification_report(y_val, y_val_pred))\n",
    "    print(\"------------------------------------------\")\n",
    "\n",
    "    # Test Data\n",
    "    print(\"Testing using test data:\")\n",
    "    y_test_pred = clf.predict(X_test)\n",
    "    print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection with all added features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_added_features_scaled = pd.read_csv(\"../../Data/Final datasets/train_data.csv\")\n",
    "# val_data_added_features_scaled = pd.read_csv(\"../../Data/Final datasets/val_data.csv\")\n",
    "test_data_added_features_scaled = pd.read_csv(\"../../Data/Final datasets/test_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_data_added_features_scaled[\"class_label\"].values\n",
    "y_test = test_data_added_features_scaled[\"class_label\"].values\n",
    "# y_val = val_data_features[\"class_label\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing using test data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.90      0.89      6361\n",
      "           1       0.90      0.88      0.89      6660\n",
      "\n",
      "    accuracy                           0.89     13021\n",
      "   macro avg       0.89      0.89      0.89     13021\n",
      "weighted avg       0.89      0.89      0.89     13021\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# with 134 features\n",
    "tfidf_vectorizer = TfidfVectorizer(analyzer='word', stop_words='english', ngram_range=(1,2), min_df=0.15)\n",
    "\n",
    "# Create mapper object to combine added features and tfidf word vectors\n",
    "mapper = DataFrameMapper([\n",
    "    (['char_count', 'word_count', 'sentence_count', 'prop_unique_words',\n",
    "    'avg_sentence_length', 'prop_punctuations', 'prop_stopwords',\n",
    "    'prop_words_in_quotes', 'prop_nouns', 'prop_verbs', 'prop_adjectives',\n",
    "    'prop_discourse_relations', 'textblob_sentiment'], None), \n",
    "    ('text_preprocessed', tfidf_vectorizer)\n",
    "])\n",
    "\n",
    "X_train_added_features = mapper.fit_transform(train_data_added_features_scaled)\n",
    "X_test_added_features = mapper.transform(test_data_added_features_scaled)\n",
    "\n",
    "clf.fit(X_train_added_features, y_train)\n",
    "\n",
    "# Test Data\n",
    "print(\"Testing using test data:\")\n",
    "y_test_pred = clf.predict(X_test_added_features)\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing using test data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.93      6361\n",
      "           1       0.94      0.93      0.94      6660\n",
      "\n",
      "    accuracy                           0.94     13021\n",
      "   macro avg       0.93      0.94      0.94     13021\n",
      "weighted avg       0.94      0.94      0.94     13021\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# with 3k features\n",
    "tfidf_vectorizer = TfidfVectorizer(analyzer='word', stop_words='english', ngram_range=(1,2), min_df=0.01)\n",
    "\n",
    "# Create mapper object to combine added features and tfidf word vectors\n",
    "mapper = DataFrameMapper([\n",
    "    (['char_count', 'word_count', 'sentence_count', 'prop_unique_words',\n",
    "    'avg_sentence_length', 'prop_punctuations', 'prop_stopwords',\n",
    "    'prop_words_in_quotes', 'prop_nouns', 'prop_verbs', 'prop_adjectives',\n",
    "    'prop_discourse_relations', 'textblob_sentiment'], None), \n",
    "    ('text_preprocessed', tfidf_vectorizer)\n",
    "])\n",
    "\n",
    "X_train_added_features = mapper.fit_transform(train_data_added_features_scaled)\n",
    "X_test_added_features = mapper.transform(test_data_added_features_scaled)\n",
    "\n",
    "clf.fit(X_train_added_features, y_train)\n",
    "\n",
    "# Test Data\n",
    "print(\"Testing using test data:\")\n",
    "y_test_pred = clf.predict(X_test_added_features)\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection with selected added features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing using test data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.88      0.88      6361\n",
      "           1       0.88      0.89      0.89      6660\n",
      "\n",
      "    accuracy                           0.88     13021\n",
      "   macro avg       0.88      0.88      0.88     13021\n",
      "weighted avg       0.88      0.88      0.88     13021\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# with 134 features\n",
    "tfidf_vectorizer = TfidfVectorizer(analyzer='word', stop_words='english', ngram_range=(1,2), min_df=0.15)\n",
    "\n",
    "# Create mapper object to combine added features and tfidf word vectors\n",
    "mapper = DataFrameMapper([\n",
    "    (['char_count', 'word_count', 'prop_unique_words', 'avg_sentence_length', 'prop_punctuations', 'prop_stopwords', 'prop_nouns'], None), \n",
    "    ('text_preprocessed', tfidf_vectorizer)\n",
    "])\n",
    "\n",
    "X_train_added_features = mapper.fit_transform(train_data_added_features_scaled)\n",
    "X_test_added_features = mapper.transform(test_data_added_features_scaled)\n",
    "\n",
    "clf.fit(X_train_added_features, y_train)\n",
    "\n",
    "# Test Data\n",
    "print(\"Testing using test data:\")\n",
    "y_test_pred = clf.predict(X_test_added_features)\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing using test data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.93      6361\n",
      "           1       0.94      0.93      0.94      6660\n",
      "\n",
      "    accuracy                           0.94     13021\n",
      "   macro avg       0.94      0.94      0.94     13021\n",
      "weighted avg       0.94      0.94      0.94     13021\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# with 3k features\n",
    "tfidf_vectorizer = TfidfVectorizer(analyzer='word', stop_words='english', ngram_range=(1,2), min_df=0.01)\n",
    "\n",
    "# Create mapper object to combine added features and tfidf word vectors\n",
    "mapper = DataFrameMapper([\n",
    "    (['char_count', 'word_count', 'prop_unique_words', 'avg_sentence_length', 'prop_punctuations', 'prop_stopwords', 'prop_nouns'], None), \n",
    "    ('text_preprocessed', tfidf_vectorizer)\n",
    "])\n",
    "\n",
    "X_train_added_features = mapper.fit_transform(train_data_added_features_scaled)\n",
    "X_test_added_features = mapper.transform(test_data_added_features_scaled)\n",
    "\n",
    "clf.fit(X_train_added_features, y_train)\n",
    "\n",
    "# Test Data\n",
    "print(\"Testing using test data:\")\n",
    "y_test_pred = clf.predict(X_test_added_features)\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
