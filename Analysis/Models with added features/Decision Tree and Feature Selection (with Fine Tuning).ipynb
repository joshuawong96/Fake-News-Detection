{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV \n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report,confusion_matrix, ConfusionMatrixDisplay, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>prop_unique_words</th>\n",
       "      <th>avg_sentence_length</th>\n",
       "      <th>prop_punctuations</th>\n",
       "      <th>prop_stopwords</th>\n",
       "      <th>prop_words_in_quotes</th>\n",
       "      <th>prop_nouns</th>\n",
       "      <th>prop_verbs</th>\n",
       "      <th>prop_adjectives</th>\n",
       "      <th>prop_discourse_relations</th>\n",
       "      <th>textblob_sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>class_label</th>\n",
       "      <th>text_preprocessed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7329</th>\n",
       "      <td>7329</td>\n",
       "      <td>0.525680</td>\n",
       "      <td>0.519298</td>\n",
       "      <td>0.305247</td>\n",
       "      <td>0.553054</td>\n",
       "      <td>0.654484</td>\n",
       "      <td>0.322593</td>\n",
       "      <td>0.856301</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.452760</td>\n",
       "      <td>0.566128</td>\n",
       "      <td>0.620464</td>\n",
       "      <td>0.185606</td>\n",
       "      <td>0.494083</td>\n",
       "      <td>Soy should not be consumed in significant quan...</td>\n",
       "      <td>1</td>\n",
       "      <td>soy consum signific quantiti unless ferment tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37228</th>\n",
       "      <td>37228</td>\n",
       "      <td>0.430449</td>\n",
       "      <td>0.435444</td>\n",
       "      <td>0.223589</td>\n",
       "      <td>0.818618</td>\n",
       "      <td>0.626127</td>\n",
       "      <td>0.389969</td>\n",
       "      <td>0.833284</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.530901</td>\n",
       "      <td>0.572455</td>\n",
       "      <td>0.506583</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.500781</td>\n",
       "      <td>Democrat Mayor Proclaims He’s Barring Trump Fr...</td>\n",
       "      <td>1</td>\n",
       "      <td>democrat mayor proclaim he bar trump enter st ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34563</th>\n",
       "      <td>34563</td>\n",
       "      <td>0.584520</td>\n",
       "      <td>0.588909</td>\n",
       "      <td>0.501643</td>\n",
       "      <td>0.411430</td>\n",
       "      <td>0.547206</td>\n",
       "      <td>0.405266</td>\n",
       "      <td>0.869145</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.460528</td>\n",
       "      <td>0.644164</td>\n",
       "      <td>0.479209</td>\n",
       "      <td>0.275591</td>\n",
       "      <td>0.557891</td>\n",
       "      <td>Trump Just Accidentally Confirmed Russian Con...</td>\n",
       "      <td>1</td>\n",
       "      <td>trump accident confirm russian contact session...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11993</th>\n",
       "      <td>11993</td>\n",
       "      <td>0.576491</td>\n",
       "      <td>0.576252</td>\n",
       "      <td>0.489896</td>\n",
       "      <td>0.565649</td>\n",
       "      <td>0.542336</td>\n",
       "      <td>0.421679</td>\n",
       "      <td>0.829616</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.508338</td>\n",
       "      <td>0.581813</td>\n",
       "      <td>0.523673</td>\n",
       "      <td>0.325942</td>\n",
       "      <td>0.544597</td>\n",
       "      <td>WATCH: Angry White Actors Have Silent Meltdow...</td>\n",
       "      <td>1</td>\n",
       "      <td>watch angri white actor silent meltdown meryl ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20643</th>\n",
       "      <td>20643</td>\n",
       "      <td>0.582368</td>\n",
       "      <td>0.586367</td>\n",
       "      <td>0.422957</td>\n",
       "      <td>0.549625</td>\n",
       "      <td>0.623866</td>\n",
       "      <td>0.288776</td>\n",
       "      <td>0.853268</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.486701</td>\n",
       "      <td>0.578983</td>\n",
       "      <td>0.574013</td>\n",
       "      <td>0.211694</td>\n",
       "      <td>0.541721</td>\n",
       "      <td>Trump’s Barely Literate Note Left At Israel H...</td>\n",
       "      <td>1</td>\n",
       "      <td>trump bare liter note left israel holocaust me...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  char_count  word_count  sentence_count  prop_unique_words  \\\n",
       "7329         7329    0.525680    0.519298        0.305247           0.553054   \n",
       "37228       37228    0.430449    0.435444        0.223589           0.818618   \n",
       "34563       34563    0.584520    0.588909        0.501643           0.411430   \n",
       "11993       11993    0.576491    0.576252        0.489896           0.565649   \n",
       "20643       20643    0.582368    0.586367        0.422957           0.549625   \n",
       "\n",
       "       avg_sentence_length  prop_punctuations  prop_stopwords  \\\n",
       "7329              0.654484           0.322593        0.856301   \n",
       "37228             0.626127           0.389969        0.833284   \n",
       "34563             0.547206           0.405266        0.869145   \n",
       "11993             0.542336           0.421679        0.829616   \n",
       "20643             0.623866           0.288776        0.853268   \n",
       "\n",
       "       prop_words_in_quotes  prop_nouns  prop_verbs  prop_adjectives  \\\n",
       "7329                    1.0    0.452760    0.566128         0.620464   \n",
       "37228                   1.0    0.530901    0.572455         0.506583   \n",
       "34563                   1.0    0.460528    0.644164         0.479209   \n",
       "11993                   1.0    0.508338    0.581813         0.523673   \n",
       "20643                   1.0    0.486701    0.578983         0.574013   \n",
       "\n",
       "       prop_discourse_relations  textblob_sentiment  \\\n",
       "7329                   0.185606            0.494083   \n",
       "37228                  0.116667            0.500781   \n",
       "34563                  0.275591            0.557891   \n",
       "11993                  0.325942            0.544597   \n",
       "20643                  0.211694            0.541721   \n",
       "\n",
       "                                                    text  class_label  \\\n",
       "7329   Soy should not be consumed in significant quan...            1   \n",
       "37228  Democrat Mayor Proclaims He’s Barring Trump Fr...            1   \n",
       "34563   Trump Just Accidentally Confirmed Russian Con...            1   \n",
       "11993   WATCH: Angry White Actors Have Silent Meltdow...            1   \n",
       "20643   Trump’s Barely Literate Note Left At Israel H...            1   \n",
       "\n",
       "                                       text_preprocessed  \n",
       "7329   soy consum signific quantiti unless ferment tr...  \n",
       "37228  democrat mayor proclaim he bar trump enter st ...  \n",
       "34563  trump accident confirm russian contact session...  \n",
       "11993  watch angri white actor silent meltdown meryl ...  \n",
       "20643  trump bare liter note left israel holocaust me...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv(\"../../Data/Final datasets/train_data.csv\")\n",
    "val_data = pd.read_csv(\"../../Data/Final datasets/val_data.csv\")\n",
    "test_data = pd.read_csv(\"../../Data/Final datasets/test_data.csv\")\n",
    "\n",
    "train_data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_text = train_data[\"text_preprocessed\"].values\n",
    "y_train = train_data[\"class_label\"].values\n",
    "\n",
    "X_val_text = val_data[\"text_preprocessed\"].values\n",
    "y_val = val_data[\"class_label\"].values\n",
    "\n",
    "X_test_text = test_data[\"text_preprocessed\"].values\n",
    "y_test = test_data[\"class_label\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model (Decision Tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fine tuning parameters\n",
    "dt = DecisionTreeClassifier()\n",
    "pipe = Pipeline(steps=[('dt', dt)])\n",
    "criterion = ['gini', 'entropy']\n",
    "max_depth = [12, 14, 16, 18, 20, 22]\n",
    "parameters = dict(dt__criterion = criterion, dt__max_depth = max_depth)\n",
    "\n",
    "# initialise Decision Tree\n",
    "# clf = DecisionTreeClassifier(criterion='entropy',random_state=0)\n",
    "clf = GridSearchCV(pipe, parameters) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Tf-ldf\n",
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing using validation data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.90      0.91      6361\n",
      "           1       0.91      0.92      0.91      6659\n",
      "\n",
      "    accuracy                           0.91     13020\n",
      "   macro avg       0.91      0.91      0.91     13020\n",
      "weighted avg       0.91      0.91      0.91     13020\n",
      "\n",
      "------------------------------------------\n",
      "Testing using test data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.91      0.92      6361\n",
      "           1       0.91      0.93      0.92      6660\n",
      "\n",
      "    accuracy                           0.92     13021\n",
      "   macro avg       0.92      0.92      0.92     13021\n",
      "weighted avg       0.92      0.92      0.92     13021\n",
      "\n",
      "------------------------------------------\n",
      "Best Parameters: {'dt__criterion': 'gini', 'dt__max_depth': 12}\n"
     ]
    }
   ],
   "source": [
    "# with 134 features\n",
    "tfidf_vectorizer = TfidfVectorizer(analyzer='word', stop_words='english', ngram_range=(1,2), min_df=0.15)\n",
    "tfidf_vectorizer.fit(X_train_text)\n",
    "\n",
    "X_train = tfidf_vectorizer.transform(X_train_text)\n",
    "X_val = tfidf_vectorizer.transform(X_val_text)\n",
    "X_test = tfidf_vectorizer.transform(X_test_text)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Validation Data\n",
    "print(\"Testing using validation data:\")    \n",
    "y_val_pred = clf.predict(X_val)\n",
    "print(classification_report(y_val, y_val_pred))\n",
    "print(\"------------------------------------------\")\n",
    "\n",
    "# Test Data\n",
    "print(\"Testing using test data:\")  \n",
    "y_test_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "print(\"------------------------------------------\")\n",
    "\n",
    "print(\"Best Parameters:\", clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing using validation data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.95      6361\n",
      "           1       0.95      0.97      0.96      6659\n",
      "\n",
      "    accuracy                           0.95     13020\n",
      "   macro avg       0.96      0.95      0.95     13020\n",
      "weighted avg       0.96      0.95      0.95     13020\n",
      "\n",
      "------------------------------------------\n",
      "Testing using test data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95      6361\n",
      "           1       0.95      0.96      0.95      6660\n",
      "\n",
      "    accuracy                           0.95     13021\n",
      "   macro avg       0.95      0.95      0.95     13021\n",
      "weighted avg       0.95      0.95      0.95     13021\n",
      "\n",
      "------------------------------------------\n",
      "Best Parameters: {'dt__criterion': 'gini', 'dt__max_depth': 12}\n"
     ]
    }
   ],
   "source": [
    "# with 3k features\n",
    "tfidf_vectorizer = TfidfVectorizer(analyzer='word', stop_words='english', ngram_range=(1,2), min_df=0.01)\n",
    "tfidf_vectorizer.fit(X_train_text)\n",
    "\n",
    "X_train = tfidf_vectorizer.transform(X_train_text)\n",
    "X_val = tfidf_vectorizer.transform(X_val_text)\n",
    "X_test = tfidf_vectorizer.transform(X_test_text)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Validation Data\n",
    "print(\"Testing using validation data:\")    \n",
    "y_val_pred = clf.predict(X_val)\n",
    "print(classification_report(y_val, y_val_pred))\n",
    "print(\"------------------------------------------\")\n",
    "\n",
    "# Test Data\n",
    "print(\"Testing using test data:\")\n",
    "y_test_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "print(\"------------------------------------------\")\n",
    "\n",
    "print(\"Best Parameters:\", clf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection with all added features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_added_features_scaled = pd.read_csv(\"../../Data/Final datasets/train_data.csv\")\n",
    "# val_data_added_features_scaled = pd.read_csv(\"../../Data/Final datasets/val_data.csv\")\n",
    "test_data_added_features_scaled = pd.read_csv(\"../../Data/Final datasets/test_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_data_added_features_scaled[\"class_label\"].values\n",
    "y_test = test_data_added_features_scaled[\"class_label\"].values\n",
    "# y_val = val_data_features[\"class_label\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing using test data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.91      0.91      6361\n",
      "           1       0.91      0.91      0.91      6660\n",
      "\n",
      "    accuracy                           0.91     13021\n",
      "   macro avg       0.91      0.91      0.91     13021\n",
      "weighted avg       0.91      0.91      0.91     13021\n",
      "\n",
      "------------------------------------------\n",
      "Best Parameters: {'dt__criterion': 'gini', 'dt__max_depth': 14}\n"
     ]
    }
   ],
   "source": [
    "# with 134 features\n",
    "tfidf_vectorizer = TfidfVectorizer(analyzer='word', stop_words='english', ngram_range=(1,2), min_df=0.15)\n",
    "\n",
    "# Create mapper object to combine added features and tfidf word vectors\n",
    "mapper = DataFrameMapper([\n",
    "    (['char_count', 'word_count', 'sentence_count', 'prop_unique_words',\n",
    "    'avg_sentence_length', 'prop_punctuations', 'prop_stopwords',\n",
    "    'prop_words_in_quotes', 'prop_nouns', 'prop_verbs', 'prop_adjectives',\n",
    "    'prop_discourse_relations', 'textblob_sentiment'], None), \n",
    "    ('text_preprocessed', tfidf_vectorizer)\n",
    "])\n",
    "\n",
    "X_train_added_features = mapper.fit_transform(train_data_added_features_scaled)\n",
    "X_test_added_features = mapper.transform(test_data_added_features_scaled)\n",
    "\n",
    "clf.fit(X_train_added_features, y_train)\n",
    "\n",
    "# Test Data\n",
    "print(\"Testing using test data:\")\n",
    "y_test_pred = clf.predict(X_test_added_features)\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "print(\"------------------------------------------\")\n",
    "\n",
    "print(\"Best Parameters:\", clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing using test data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94      6361\n",
      "           1       0.95      0.95      0.95      6660\n",
      "\n",
      "    accuracy                           0.95     13021\n",
      "   macro avg       0.95      0.95      0.95     13021\n",
      "weighted avg       0.95      0.95      0.95     13021\n",
      "\n",
      "------------------------------------------\n",
      "Best Parameters: {'dt__criterion': 'gini', 'dt__max_depth': 12}\n"
     ]
    }
   ],
   "source": [
    "# with 3k features\n",
    "tfidf_vectorizer = TfidfVectorizer(analyzer='word', stop_words='english', ngram_range=(1,2), min_df=0.01)\n",
    "\n",
    "# Create mapper object to combine added features and tfidf word vectors\n",
    "mapper = DataFrameMapper([\n",
    "    (['char_count', 'word_count', 'sentence_count', 'prop_unique_words',\n",
    "    'avg_sentence_length', 'prop_punctuations', 'prop_stopwords',\n",
    "    'prop_words_in_quotes', 'prop_nouns', 'prop_verbs', 'prop_adjectives',\n",
    "    'prop_discourse_relations', 'textblob_sentiment'], None), \n",
    "    ('text_preprocessed', tfidf_vectorizer)\n",
    "])\n",
    "\n",
    "X_train_added_features = mapper.fit_transform(train_data_added_features_scaled)\n",
    "X_test_added_features = mapper.transform(test_data_added_features_scaled)\n",
    "\n",
    "clf.fit(X_train_added_features, y_train)\n",
    "\n",
    "# Test Data\n",
    "print(\"Testing using test data:\")\n",
    "y_test_pred = clf.predict(X_test_added_features)\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "print(\"------------------------------------------\")\n",
    "\n",
    "print(\"Best Parameters:\", clf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection with selected added features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing using test data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.90      0.90      6361\n",
      "           1       0.90      0.90      0.90      6660\n",
      "\n",
      "    accuracy                           0.90     13021\n",
      "   macro avg       0.90      0.90      0.90     13021\n",
      "weighted avg       0.90      0.90      0.90     13021\n",
      "\n",
      "------------------------------------------\n",
      "Best Parameters: {'dt__criterion': 'gini', 'dt__max_depth': 12}\n"
     ]
    }
   ],
   "source": [
    "# with 134 features\n",
    "tfidf_vectorizer = TfidfVectorizer(analyzer='word', stop_words='english', ngram_range=(1,2), min_df=0.15)\n",
    "\n",
    "# Create mapper object to combine added features and tfidf word vectors\n",
    "mapper = DataFrameMapper([\n",
    "    (['char_count', 'word_count', 'prop_unique_words', 'avg_sentence_length', 'prop_punctuations', 'prop_stopwords', 'prop_nouns'], None), \n",
    "    ('text_preprocessed', tfidf_vectorizer)\n",
    "])\n",
    "\n",
    "X_train_added_features = mapper.fit_transform(train_data_added_features_scaled)\n",
    "X_test_added_features = mapper.transform(test_data_added_features_scaled)\n",
    "\n",
    "clf.fit(X_train_added_features, y_train)\n",
    "\n",
    "# Test Data\n",
    "print(\"Testing using test data:\")\n",
    "y_test_pred = clf.predict(X_test_added_features)\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "print(\"------------------------------------------\")\n",
    "\n",
    "print(\"Best Parameters:\", clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing using test data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.94      6361\n",
      "           1       0.95      0.95      0.95      6660\n",
      "\n",
      "    accuracy                           0.95     13021\n",
      "   macro avg       0.95      0.95      0.95     13021\n",
      "weighted avg       0.95      0.95      0.95     13021\n",
      "\n",
      "------------------------------------------\n",
      "Best Parameters: {'dt__criterion': 'gini', 'dt__max_depth': 12}\n"
     ]
    }
   ],
   "source": [
    "# with 3k features\n",
    "tfidf_vectorizer = TfidfVectorizer(analyzer='word', stop_words='english', ngram_range=(1,2), min_df=0.01)\n",
    "\n",
    "# Create mapper object to combine added features and tfidf word vectors\n",
    "mapper = DataFrameMapper([\n",
    "    (['char_count', 'word_count', 'prop_unique_words', 'avg_sentence_length', 'prop_punctuations', 'prop_stopwords', 'prop_nouns'], None), \n",
    "    ('text_preprocessed', tfidf_vectorizer)\n",
    "])\n",
    "\n",
    "X_train_added_features = mapper.fit_transform(train_data_added_features_scaled)\n",
    "X_test_added_features = mapper.transform(test_data_added_features_scaled)\n",
    "\n",
    "clf.fit(X_train_added_features, y_train)\n",
    "\n",
    "# Test Data\n",
    "print(\"Testing using test data:\")\n",
    "y_test_pred = clf.predict(X_test_added_features)\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "print(\"------------------------------------------\")\n",
    "\n",
    "print(\"Best Parameters:\", clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
