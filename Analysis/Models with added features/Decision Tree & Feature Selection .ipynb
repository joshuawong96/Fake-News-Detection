{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acer\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\compat\\_optional.py:138: UserWarning: Pandas requires version '2.7.0' or newer of 'numexpr' (version '2.6.9' currently installed).\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# Import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report,confusion_matrix, ConfusionMatrixDisplay, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>prop_unique_words</th>\n",
       "      <th>avg_sentence_length</th>\n",
       "      <th>prop_punctuations</th>\n",
       "      <th>prop_stopwords</th>\n",
       "      <th>prop_words_in_quotes</th>\n",
       "      <th>prop_nouns</th>\n",
       "      <th>prop_verbs</th>\n",
       "      <th>prop_adjectives</th>\n",
       "      <th>prop_discourse_relations</th>\n",
       "      <th>textblob_sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>class_label</th>\n",
       "      <th>text_preprocessed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26609</th>\n",
       "      <td>26609</td>\n",
       "      <td>0.666917</td>\n",
       "      <td>0.659978</td>\n",
       "      <td>0.559218</td>\n",
       "      <td>0.440509</td>\n",
       "      <td>0.583070</td>\n",
       "      <td>0.340252</td>\n",
       "      <td>0.841269</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.533927</td>\n",
       "      <td>0.618542</td>\n",
       "      <td>0.508305</td>\n",
       "      <td>0.282543</td>\n",
       "      <td>0.535695</td>\n",
       "      <td>Fellow Republicans rebuke Trump over governmen...</td>\n",
       "      <td>0</td>\n",
       "      <td>fellow republican rebuk trump govern shutdown ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29157</th>\n",
       "      <td>29157</td>\n",
       "      <td>0.603781</td>\n",
       "      <td>0.610783</td>\n",
       "      <td>0.501643</td>\n",
       "      <td>0.526351</td>\n",
       "      <td>0.576269</td>\n",
       "      <td>0.387325</td>\n",
       "      <td>0.861490</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.507508</td>\n",
       "      <td>0.612994</td>\n",
       "      <td>0.507395</td>\n",
       "      <td>0.325321</td>\n",
       "      <td>0.576280</td>\n",
       "      <td>Damien Chazelle, ‘La La Land’ Director, on Cal...</td>\n",
       "      <td>0</td>\n",
       "      <td>damien chazel la la land director california a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11538</th>\n",
       "      <td>11538</td>\n",
       "      <td>0.563366</td>\n",
       "      <td>0.557473</td>\n",
       "      <td>0.429420</td>\n",
       "      <td>0.536317</td>\n",
       "      <td>0.578900</td>\n",
       "      <td>0.322225</td>\n",
       "      <td>0.835132</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.563106</td>\n",
       "      <td>0.603683</td>\n",
       "      <td>0.510901</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>0.461483</td>\n",
       "      <td>Controversial Milwaukee County sheriff says ta...</td>\n",
       "      <td>0</td>\n",
       "      <td>controversi milwauke counti sheriff say take u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19374</th>\n",
       "      <td>19374</td>\n",
       "      <td>0.715887</td>\n",
       "      <td>0.711323</td>\n",
       "      <td>0.629687</td>\n",
       "      <td>0.370864</td>\n",
       "      <td>0.579614</td>\n",
       "      <td>0.328084</td>\n",
       "      <td>0.862529</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.471117</td>\n",
       "      <td>0.600421</td>\n",
       "      <td>0.563037</td>\n",
       "      <td>0.235367</td>\n",
       "      <td>0.543917</td>\n",
       "      <td>Neuroscientist Says Fasting Reduces the Risk o...</td>\n",
       "      <td>1</td>\n",
       "      <td>neuroscientist say fast reduc risk brain disea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4872</th>\n",
       "      <td>4872</td>\n",
       "      <td>0.610511</td>\n",
       "      <td>0.609927</td>\n",
       "      <td>0.472508</td>\n",
       "      <td>0.513272</td>\n",
       "      <td>0.604768</td>\n",
       "      <td>0.331432</td>\n",
       "      <td>0.837756</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.508367</td>\n",
       "      <td>0.589346</td>\n",
       "      <td>0.545674</td>\n",
       "      <td>0.271405</td>\n",
       "      <td>0.524322</td>\n",
       "      <td>TRUMP THREATENS TO SUE ILLEGAL IMMIGRANT ACTIV...</td>\n",
       "      <td>1</td>\n",
       "      <td>trump threaten sue illeg immigr activist fav o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  char_count  word_count  sentence_count  prop_unique_words  \\\n",
       "26609       26609    0.666917    0.659978        0.559218           0.440509   \n",
       "29157       29157    0.603781    0.610783        0.501643           0.526351   \n",
       "11538       11538    0.563366    0.557473        0.429420           0.536317   \n",
       "19374       19374    0.715887    0.711323        0.629687           0.370864   \n",
       "4872         4872    0.610511    0.609927        0.472508           0.513272   \n",
       "\n",
       "       avg_sentence_length  prop_punctuations  prop_stopwords  \\\n",
       "26609             0.583070           0.340252        0.841269   \n",
       "29157             0.576269           0.387325        0.861490   \n",
       "11538             0.578900           0.322225        0.835132   \n",
       "19374             0.579614           0.328084        0.862529   \n",
       "4872              0.604768           0.331432        0.837756   \n",
       "\n",
       "       prop_words_in_quotes  prop_nouns  prop_verbs  prop_adjectives  \\\n",
       "26609                   1.0    0.533927    0.618542         0.508305   \n",
       "29157                   1.0    0.507508    0.612994         0.507395   \n",
       "11538                   1.0    0.563106    0.603683         0.510901   \n",
       "19374                   1.0    0.471117    0.600421         0.563037   \n",
       "4872                    1.0    0.508367    0.589346         0.545674   \n",
       "\n",
       "       prop_discourse_relations  textblob_sentiment  \\\n",
       "26609                  0.282543            0.535695   \n",
       "29157                  0.325321            0.576280   \n",
       "11538                  0.259259            0.461483   \n",
       "19374                  0.235367            0.543917   \n",
       "4872                   0.271405            0.524322   \n",
       "\n",
       "                                                    text  class_label  \\\n",
       "26609  Fellow Republicans rebuke Trump over governmen...            0   \n",
       "29157  Damien Chazelle, ‘La La Land’ Director, on Cal...            0   \n",
       "11538  Controversial Milwaukee County sheriff says ta...            0   \n",
       "19374  Neuroscientist Says Fasting Reduces the Risk o...            1   \n",
       "4872   TRUMP THREATENS TO SUE ILLEGAL IMMIGRANT ACTIV...            1   \n",
       "\n",
       "                                       text_preprocessed  \n",
       "26609  fellow republican rebuk trump govern shutdown ...  \n",
       "29157  damien chazel la la land director california a...  \n",
       "11538  controversi milwauke counti sheriff say take u...  \n",
       "19374  neuroscientist say fast reduc risk brain disea...  \n",
       "4872   trump threaten sue illeg immigr activist fav o...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv(\"../../Data/Final datasets/train_data.csv\")\n",
    "val_data = pd.read_csv(\"../../Data/Final datasets/val_data.csv\")\n",
    "test_data = pd.read_csv(\"../../Data/Final datasets/test_data.csv\")\n",
    "\n",
    "train_data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_text = train_data[\"text_preprocessed\"].values\n",
    "y_train = train_data[\"class_label\"].values\n",
    "\n",
    "X_val_text = val_data[\"text_preprocessed\"].values\n",
    "y_val = val_data[\"class_label\"].values\n",
    "\n",
    "X_test_text = test_data[\"text_preprocessed\"].values\n",
    "y_test = test_data[\"class_label\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model (Decision Tree)\n",
    "## Using CountVectoriser with Bag of Words, Unigrams + Bigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using 134 and 3k features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with 134 features\n",
    "vectorizer = CountVectorizer(stop_words='english', ngram_range=(1,2), min_df=0.15)\n",
    "vectorizer.fit(X_train_text)\n",
    "\n",
    "X_train = vectorizer.transform(X_train_text)\n",
    "X_val = vectorizer.transform(X_val_text)\n",
    "X_test = vectorizer.transform(X_test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of features used: 134\n"
     ]
    }
   ],
   "source": [
    "print(\"number of features used:\", len(vectorizer.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(random_state=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialise Decision Tree\n",
    "clf = DecisionTreeClassifier(criterion='gini', random_state=0) \n",
    "\n",
    "# train model\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.89      0.90      6361\n",
      "           1       0.90      0.91      0.90      6659\n",
      "\n",
      "    accuracy                           0.90     13020\n",
      "   macro avg       0.90      0.90      0.90     13020\n",
      "weighted avg       0.90      0.90      0.90     13020\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_val_pred = clf.predict(X_val)\n",
    "print(classification_report(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.90      0.90      6361\n",
      "           1       0.91      0.91      0.91      6660\n",
      "\n",
      "    accuracy                           0.91     13021\n",
      "   macro avg       0.91      0.91      0.91     13021\n",
      "weighted avg       0.91      0.91      0.91     13021\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.tree import export_graphviz\n",
    "# import pydotplus\n",
    "# from six import StringIO  \n",
    "# from IPython.display import Image\n",
    "\n",
    "# feature_cols = ['text_preprocessed']\n",
    "\n",
    "# dot_data = StringIO()\n",
    "# export_graphviz(clf, out_file = dot_data, \n",
    "#                       feature_names = feature_cols,  \n",
    "#                      filled = True, rounded = True,  \n",
    "#                     special_characters = True)\n",
    "\n",
    "# graph = pydotplus.graph_from_dot_data(dot_data.getvalue())\n",
    "# Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.tree import plot_tree\n",
    "\n",
    "# plot_tree(clf.fit(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  with 3k features\n",
    "vectorizer = CountVectorizer(stop_words='english', ngram_range=(1,2), min_df=0.01)\n",
    "vectorizer.fit(X_train_text)\n",
    "\n",
    "X_train = vectorizer.transform(X_train_text)\n",
    "X_val = vectorizer.transform(X_val_text)\n",
    "X_test = vectorizer.transform(X_test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(random_state=0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train model\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.95      6361\n",
      "           1       0.95      0.95      0.95      6659\n",
      "\n",
      "    accuracy                           0.95     13020\n",
      "   macro avg       0.95      0.95      0.95     13020\n",
      "weighted avg       0.95      0.95      0.95     13020\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_val_pred = clf.predict(X_val)\n",
    "print(classification_report(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.95      6361\n",
      "           1       0.95      0.95      0.95      6660\n",
      "\n",
      "    accuracy                           0.95     13021\n",
      "   macro avg       0.95      0.95      0.95     13021\n",
      "weighted avg       0.95      0.95      0.95     13021\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Tf-ldf\n",
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with unigram and bigram\n",
      "Testing using validation data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.89      0.90      6361\n",
      "           1       0.90      0.91      0.91      6659\n",
      "\n",
      "    accuracy                           0.90     13020\n",
      "   macro avg       0.90      0.90      0.90     13020\n",
      "weighted avg       0.90      0.90      0.90     13020\n",
      "\n",
      "------------------------------------------\n",
      "Testing using test data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.90      0.91      6361\n",
      "           1       0.91      0.92      0.91      6660\n",
      "\n",
      "    accuracy                           0.91     13021\n",
      "   macro avg       0.91      0.91      0.91     13021\n",
      "weighted avg       0.91      0.91      0.91     13021\n",
      "\n",
      "------------------------------------------\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# with 134 features\n",
    "tfidf_params = {'unigram and bigram': (1,2)}\n",
    "\n",
    "for ngram, values in tfidf_params.items():\n",
    "    tfidf_vectorizer = TfidfVectorizer(analyzer='word', stop_words='english', ngram_range=values, min_df=0.15)\n",
    "    tfidf_vectorizer.fit(X_train_text)\n",
    "\n",
    "    X_train = tfidf_vectorizer.transform(X_train_text)\n",
    "    X_val = tfidf_vectorizer.transform(X_val_text)\n",
    "    X_test = tfidf_vectorizer.transform(X_test_text)\n",
    "\n",
    "    print(f\"Model with {ngram}\")\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Validation Data\n",
    "    print(\"Testing using validation data:\")    \n",
    "    y_val_pred = clf.predict(X_val)\n",
    "    print(classification_report(y_val, y_val_pred))\n",
    "    print(\"------------------------------------------\")\n",
    "\n",
    "    # Test Data\n",
    "    print(\"Testing using test data:\")  \n",
    "    y_test_pred = clf.predict(X_test)\n",
    "    print(classification_report(y_test, y_test_pred))\n",
    "    print(\"------------------------------------------\")\n",
    "    print(\"------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with unigram and bigram\n",
      "Testing using validation data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.95      6361\n",
      "           1       0.94      0.95      0.95      6659\n",
      "\n",
      "    accuracy                           0.95     13020\n",
      "   macro avg       0.95      0.95      0.95     13020\n",
      "weighted avg       0.95      0.95      0.95     13020\n",
      "\n",
      "------------------------------------------\n",
      "Testing using test data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94      6361\n",
      "           1       0.94      0.95      0.95      6660\n",
      "\n",
      "    accuracy                           0.94     13021\n",
      "   macro avg       0.94      0.94      0.94     13021\n",
      "weighted avg       0.94      0.94      0.94     13021\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tfidf_params = {'unigram and bigram': (1,2)}\n",
    "\n",
    "for ngram, values in tfidf_params.items():\n",
    "    tfidf_vectorizer = TfidfVectorizer(analyzer='word', stop_words='english', ngram_range=values, min_df=0.01)\n",
    "    tfidf_vectorizer.fit(X_train_text)\n",
    "\n",
    "    X_train = tfidf_vectorizer.transform(X_train_text)\n",
    "    X_val = tfidf_vectorizer.transform(X_val_text)\n",
    "    X_test = tfidf_vectorizer.transform(X_test_text)\n",
    "\n",
    "    print(f\"Model with {ngram}\")\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Validation Data\n",
    "    print(\"Testing using validation data:\")    \n",
    "    y_val_pred = clf.predict(X_val)\n",
    "    print(classification_report(y_val, y_val_pred))\n",
    "    print(\"------------------------------------------\")\n",
    "\n",
    "    # Test Data\n",
    "    print(\"Testing using test data:\")\n",
    "    y_test_pred = clf.predict(X_test)\n",
    "    print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection with all added features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_added_features_scaled = pd.read_csv(\"../../Data/Final datasets/train_data.csv\")\n",
    "# val_data_added_features_scaled = pd.read_csv(\"../../Data/Final datasets/val_data.csv\")\n",
    "test_data_added_features_scaled = pd.read_csv(\"../../Data/Final datasets/test_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_data_added_features_scaled[\"class_label\"].values\n",
    "y_test = test_data_added_features_scaled[\"class_label\"].values\n",
    "# y_val = val_data_features[\"class_label\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing using test data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.90      0.89      6361\n",
      "           1       0.90      0.88      0.89      6660\n",
      "\n",
      "    accuracy                           0.89     13021\n",
      "   macro avg       0.89      0.89      0.89     13021\n",
      "weighted avg       0.89      0.89      0.89     13021\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# with 134 features\n",
    "tfidf_vectorizer = TfidfVectorizer(analyzer='word', stop_words='english', ngram_range=(1,2), min_df=0.15)\n",
    "\n",
    "# Create mapper object to combine added features and tfidf word vectors\n",
    "mapper = DataFrameMapper([\n",
    "    (['char_count', 'word_count', 'sentence_count', 'prop_unique_words',\n",
    "    'avg_sentence_length', 'prop_punctuations', 'prop_stopwords',\n",
    "    'prop_words_in_quotes', 'prop_nouns', 'prop_verbs', 'prop_adjectives',\n",
    "    'prop_discourse_relations', 'textblob_sentiment'], None), \n",
    "    ('text_preprocessed', tfidf_vectorizer)\n",
    "])\n",
    "\n",
    "X_train_added_features = mapper.fit_transform(train_data_added_features_scaled)\n",
    "X_test_added_features = mapper.transform(test_data_added_features_scaled)\n",
    "\n",
    "clf.fit(X_train_added_features, y_train)\n",
    "\n",
    "# Test Data\n",
    "print(\"Testing using test data:\")\n",
    "y_test_pred = clf.predict(X_test_added_features)\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing using test data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.93      6361\n",
      "           1       0.94      0.93      0.94      6660\n",
      "\n",
      "    accuracy                           0.94     13021\n",
      "   macro avg       0.93      0.94      0.94     13021\n",
      "weighted avg       0.94      0.94      0.94     13021\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# with 3k features\n",
    "tfidf_vectorizer = TfidfVectorizer(analyzer='word', stop_words='english', ngram_range=(1,2), min_df=0.01)\n",
    "\n",
    "# Create mapper object to combine added features and tfidf word vectors\n",
    "mapper = DataFrameMapper([\n",
    "    (['char_count', 'word_count', 'sentence_count', 'prop_unique_words',\n",
    "    'avg_sentence_length', 'prop_punctuations', 'prop_stopwords',\n",
    "    'prop_words_in_quotes', 'prop_nouns', 'prop_verbs', 'prop_adjectives',\n",
    "    'prop_discourse_relations', 'textblob_sentiment'], None), \n",
    "    ('text_preprocessed', tfidf_vectorizer)\n",
    "])\n",
    "\n",
    "X_train_added_features = mapper.fit_transform(train_data_added_features_scaled)\n",
    "X_test_added_features = mapper.transform(test_data_added_features_scaled)\n",
    "\n",
    "clf.fit(X_train_added_features, y_train)\n",
    "\n",
    "# Test Data\n",
    "print(\"Testing using test data:\")\n",
    "y_test_pred = clf.predict(X_test_added_features)\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection with selected added features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing using test data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.88      0.88      6361\n",
      "           1       0.88      0.89      0.89      6660\n",
      "\n",
      "    accuracy                           0.88     13021\n",
      "   macro avg       0.88      0.88      0.88     13021\n",
      "weighted avg       0.88      0.88      0.88     13021\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# with 134 features\n",
    "tfidf_vectorizer = TfidfVectorizer(analyzer='word', stop_words='english', ngram_range=(1,2), min_df=0.15)\n",
    "\n",
    "# Create mapper object to combine added features and tfidf word vectors\n",
    "mapper = DataFrameMapper([\n",
    "    (['char_count', 'word_count', 'prop_unique_words', 'avg_sentence_length', 'prop_punctuations', 'prop_stopwords', 'prop_nouns'], None), \n",
    "    ('text_preprocessed', tfidf_vectorizer)\n",
    "])\n",
    "\n",
    "X_train_added_features = mapper.fit_transform(train_data_added_features_scaled)\n",
    "X_test_added_features = mapper.transform(test_data_added_features_scaled)\n",
    "\n",
    "clf.fit(X_train_added_features, y_train)\n",
    "\n",
    "# Test Data\n",
    "print(\"Testing using test data:\")\n",
    "y_test_pred = clf.predict(X_test_added_features)\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing using test data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.93      6361\n",
      "           1       0.94      0.93      0.94      6660\n",
      "\n",
      "    accuracy                           0.94     13021\n",
      "   macro avg       0.94      0.94      0.94     13021\n",
      "weighted avg       0.94      0.94      0.94     13021\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# with 3k features\n",
    "tfidf_vectorizer = TfidfVectorizer(analyzer='word', stop_words='english', ngram_range=(1,2), min_df=0.01)\n",
    "\n",
    "# Create mapper object to combine added features and tfidf word vectors\n",
    "mapper = DataFrameMapper([\n",
    "    (['char_count', 'word_count', 'prop_unique_words', 'avg_sentence_length', 'prop_punctuations', 'prop_stopwords', 'prop_nouns'], None), \n",
    "    ('text_preprocessed', tfidf_vectorizer)\n",
    "])\n",
    "\n",
    "X_train_added_features = mapper.fit_transform(train_data_added_features_scaled)\n",
    "X_test_added_features = mapper.transform(test_data_added_features_scaled)\n",
    "\n",
    "clf.fit(X_train_added_features, y_train)\n",
    "\n",
    "# Test Data\n",
    "print(\"Testing using test data:\")\n",
    "y_test_pred = clf.predict(X_test_added_features)\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
