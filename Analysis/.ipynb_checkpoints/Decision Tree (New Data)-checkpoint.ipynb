{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report,confusion_matrix, ConfusionMatrixDisplay, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>class_label</th>\n",
       "      <th>text_preprocessed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1387</th>\n",
       "      <td>9177</td>\n",
       "      <td>Democrats want 'major role' for Sanders: Reute...</td>\n",
       "      <td>0</td>\n",
       "      <td>democrat want major role sander reutersipso po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5649</th>\n",
       "      <td>16608</td>\n",
       "      <td>Candidate Replaced by H-1B: Americans Should H...</td>\n",
       "      <td>0</td>\n",
       "      <td>candid replac h1b american input outsourcinga ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10988</th>\n",
       "      <td>23417</td>\n",
       "      <td>Chicago Community Organizers Mobilize Flash Mo...</td>\n",
       "      <td>1</td>\n",
       "      <td>chicago commun organ mobil flash mob shut trum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23046</th>\n",
       "      <td>17373</td>\n",
       "      <td>BLACK REPUBLICAN AND BRILLIANT NEUROSURGEON AN...</td>\n",
       "      <td>1</td>\n",
       "      <td>black republican brilliant neurosurgeon announ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2513</th>\n",
       "      <td>13561</td>\n",
       "      <td>BOOM! WATCH TREY GOWDY Scorch FBI Director Com...</td>\n",
       "      <td>1</td>\n",
       "      <td>boom watch trey gowdi scorch fbi director come...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                               text  \\\n",
       "1387         9177  Democrats want 'major role' for Sanders: Reute...   \n",
       "5649        16608  Candidate Replaced by H-1B: Americans Should H...   \n",
       "10988       23417  Chicago Community Organizers Mobilize Flash Mo...   \n",
       "23046       17373  BLACK REPUBLICAN AND BRILLIANT NEUROSURGEON AN...   \n",
       "2513        13561  BOOM! WATCH TREY GOWDY Scorch FBI Director Com...   \n",
       "\n",
       "       class_label                                  text_preprocessed  \n",
       "1387             0  democrat want major role sander reutersipso po...  \n",
       "5649             0  candid replac h1b american input outsourcinga ...  \n",
       "10988            1  chicago commun organ mobil flash mob shut trum...  \n",
       "23046            1  black republican brilliant neurosurgeon announ...  \n",
       "2513             1  boom watch trey gowdi scorch fbi director come...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv(\"../Data/train_data.csv\")\n",
    "val_data = pd.read_csv(\"../Data/validation_data.csv\")\n",
    "test_data = pd.read_csv(\"../Data/test_data.csv\")\n",
    "\n",
    "train_data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_text = train_data[\"text_preprocessed\"].values\n",
    "y_train = train_data[\"class_label\"].values\n",
    "\n",
    "X_val_text = val_data[\"text_preprocessed\"].values\n",
    "y_val = val_data[\"class_label\"].values\n",
    "\n",
    "X_test_text = test_data[\"text_preprocessed\"].values\n",
    "y_test = test_data[\"class_label\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model (Decision Tree)\n",
    "## Using CountVectoriser with Bag of Words, Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(stop_words='english', ngram_range=(1,1))\n",
    "vectorizer.fit(X_train_text)\n",
    "\n",
    "X_train = vectorizer.transform(X_train_text)\n",
    "X_val = vectorizer.transform(X_val_text)\n",
    "X_test = vectorizer.transform(X_test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of features used: 238266\n"
     ]
    }
   ],
   "source": [
    "print(\"number of features used:\", len(vectorizer.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(random_state=0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialise Decision Tree\n",
    "clf = DecisionTreeClassifier(criterion='gini',random_state=0) \n",
    "\n",
    "# train model\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      6361\n",
      "           1       0.96      0.96      0.96      6659\n",
      "\n",
      "    accuracy                           0.96     13020\n",
      "   macro avg       0.96      0.96      0.96     13020\n",
      "weighted avg       0.96      0.96      0.96     13020\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_val_pred = clf.predict(X_val)\n",
    "print(classification_report(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      6361\n",
      "           1       0.96      0.96      0.96      6660\n",
      "\n",
      "    accuracy                           0.96     13021\n",
      "   macro avg       0.96      0.96      0.96     13021\n",
      "weighted avg       0.96      0.96      0.96     13021\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.tree import export_graphviz\n",
    "# import pydotplus\n",
    "# from six import StringIO  \n",
    "# from IPython.display import Image\n",
    "\n",
    "# feature_cols = ['text_preprocessed']\n",
    "\n",
    "# dot_data = StringIO()\n",
    "# export_graphviz(clf, out_file = dot_data, \n",
    "#                       feature_names = feature_cols,  \n",
    "#                      filled = True, rounded = True,  \n",
    "#                     special_characters = True)\n",
    "\n",
    "# graph = pydotplus.graph_from_dot_data(dot_data.getvalue())\n",
    "# Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.tree import plot_tree\n",
    "\n",
    "# plot_tree(clf.fit(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7645</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2189</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8944</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10625</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5798</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10583</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1198</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1715</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6183</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12854</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Actual  Predicted\n",
       "7645        1          1\n",
       "2189        0          0\n",
       "8944        0          1\n",
       "10625       1          1\n",
       "5798        1          1\n",
       "10583       0          0\n",
       "1198        0          0\n",
       "1715        1          1\n",
       "6183        1          1\n",
       "12854       1          1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get predictions and compare results\n",
    "predictions = clf.predict(X_test)\n",
    "results = pd.DataFrame({'Actual': y_test, 'Predicted': predictions})\n",
    "results.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9612164964288457\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "accuracy = accuracy_score(y_test,predictions)\n",
    "print(\"Accuracy:\",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9609105885876891\n",
      "Recall: 0.9633633633633634\n",
      "F-measure: 0.9621354127614905\n"
     ]
    }
   ],
   "source": [
    "# Precision and Recall\n",
    "precision = metrics.precision_score(y_test, predictions)\n",
    "recall = metrics.recall_score(y_test, predictions)\n",
    "f_measure = metrics.f1_score(y_test, predictions)\n",
    "print(\"Precision:\",precision)\n",
    "print(\"Recall:\",recall)\n",
    "print(\"F-measure:\",f_measure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Tf-ldf and Unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with unigram\n",
      "Testing using validation data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95      6361\n",
      "           1       0.95      0.96      0.95      6659\n",
      "\n",
      "    accuracy                           0.95     13020\n",
      "   macro avg       0.95      0.95      0.95     13020\n",
      "weighted avg       0.95      0.95      0.95     13020\n",
      "\n",
      "------------------------------------------\n",
      "Testing using test data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.95      6361\n",
      "           1       0.96      0.96      0.96      6660\n",
      "\n",
      "    accuracy                           0.96     13021\n",
      "   macro avg       0.96      0.96      0.96     13021\n",
      "weighted avg       0.96      0.96      0.96     13021\n",
      "\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "Model with unigram and bigram\n",
      "Testing using validation data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.96      6361\n",
      "           1       0.96      0.96      0.96      6659\n",
      "\n",
      "    accuracy                           0.96     13020\n",
      "   macro avg       0.96      0.96      0.96     13020\n",
      "weighted avg       0.96      0.96      0.96     13020\n",
      "\n",
      "------------------------------------------\n",
      "Testing using test data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.96      6361\n",
      "           1       0.96      0.96      0.96      6660\n",
      "\n",
      "    accuracy                           0.96     13021\n",
      "   macro avg       0.96      0.96      0.96     13021\n",
      "weighted avg       0.96      0.96      0.96     13021\n",
      "\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "Model with bigram\n",
      "Testing using validation data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.91      0.91      6361\n",
      "           1       0.92      0.91      0.91      6659\n",
      "\n",
      "    accuracy                           0.91     13020\n",
      "   macro avg       0.91      0.91      0.91     13020\n",
      "weighted avg       0.91      0.91      0.91     13020\n",
      "\n",
      "------------------------------------------\n",
      "Testing using test data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91      6361\n",
      "           1       0.91      0.91      0.91      6660\n",
      "\n",
      "    accuracy                           0.91     13021\n",
      "   macro avg       0.91      0.91      0.91     13021\n",
      "weighted avg       0.91      0.91      0.91     13021\n",
      "\n",
      "------------------------------------------\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "tfidf_params = {'unigram':(1,1), 'unigram and bigram': (1,2), 'bigram':(2,2)}\n",
    "\n",
    "for ngram, values in tfidf_params.items():\n",
    "    tfidf_vectorizer = TfidfVectorizer(analyzer='word', stop_words='english', ngram_range=values)\n",
    "    tfidf_vectorizer.fit(X_train_text)\n",
    "\n",
    "    X_train = tfidf_vectorizer.transform(X_train_text)\n",
    "    X_val = tfidf_vectorizer.transform(X_val_text)\n",
    "    X_test = tfidf_vectorizer.transform(X_test_text)\n",
    "\n",
    "    print(f\"Model with {ngram}\")\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Validation Data\n",
    "    print(\"Testing using validation data:\")    \n",
    "    y_val_pred = clf.predict(X_val)\n",
    "    print(classification_report(y_val, y_val_pred))\n",
    "    print(\"------------------------------------------\")\n",
    "\n",
    "    # Test Data\n",
    "    print(\"Testing using test data:\")\n",
    "    y_test_pred = clf.predict(X_test)\n",
    "    print(classification_report(y_test, y_test_pred))\n",
    "    print(\"------------------------------------------\")\n",
    "    print(\"------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
