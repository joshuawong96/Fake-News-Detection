{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report,confusion_matrix, ConfusionMatrixDisplay, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>class_label</th>\n",
       "      <th>text_preprocessed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22729</th>\n",
       "      <td>5630</td>\n",
       "      <td>Florida GOP’s Anti-Abortion Law Struck Down I...</td>\n",
       "      <td>1</td>\n",
       "      <td>florida gop antiabort law struck anoth huge pl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9926</th>\n",
       "      <td>896</td>\n",
       "      <td>Trump taps Fed centrist Powell to lead U.S. ce...</td>\n",
       "      <td>0</td>\n",
       "      <td>trump tap fed centrist powel lead us central b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13822</th>\n",
       "      <td>18759</td>\n",
       "      <td>Coulter Calls on Trump to Impose Temporary Ban...</td>\n",
       "      <td>0</td>\n",
       "      <td>coulter call trump impos temporari ban immigr ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25693</th>\n",
       "      <td>7166</td>\n",
       "      <td>San Francisco Cops Caught Sending Racist, Hom...</td>\n",
       "      <td>1</td>\n",
       "      <td>san francisco cop caught send racist homophob ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12098</th>\n",
       "      <td>348</td>\n",
       "      <td>Trump’s UN Speech May Have Been Terrible, But...</td>\n",
       "      <td>1</td>\n",
       "      <td>trump un speech may terribl face repres pricel...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                               text  \\\n",
       "22729        5630   Florida GOP’s Anti-Abortion Law Struck Down I...   \n",
       "9926          896  Trump taps Fed centrist Powell to lead U.S. ce...   \n",
       "13822       18759  Coulter Calls on Trump to Impose Temporary Ban...   \n",
       "25693        7166   San Francisco Cops Caught Sending Racist, Hom...   \n",
       "12098         348   Trump’s UN Speech May Have Been Terrible, But...   \n",
       "\n",
       "       class_label                                  text_preprocessed  \n",
       "22729            1  florida gop antiabort law struck anoth huge pl...  \n",
       "9926             0  trump tap fed centrist powel lead us central b...  \n",
       "13822            0  coulter call trump impos temporari ban immigr ...  \n",
       "25693            1  san francisco cop caught send racist homophob ...  \n",
       "12098            1  trump un speech may terribl face repres pricel...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv(\"../Data/train_data.csv\")\n",
    "val_data = pd.read_csv(\"../Data/validation_data.csv\")\n",
    "test_data = pd.read_csv(\"../Data/test_data.csv\")\n",
    "\n",
    "train_data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_text = train_data[\"text_preprocessed\"].values\n",
    "y_train = train_data[\"class_label\"].values\n",
    "\n",
    "X_val_text = val_data[\"text_preprocessed\"].values\n",
    "y_val = val_data[\"class_label\"].values\n",
    "\n",
    "X_test_text = test_data[\"text_preprocessed\"].values\n",
    "y_test = test_data[\"class_label\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model (Random Forest)\n",
    "## Using CountVectoriser with Bag of Words, Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(stop_words='english', ngram_range=(1,1))\n",
    "vectorizer.fit(X_train_text)\n",
    "\n",
    "X_train = vectorizer.transform(X_train_text)\n",
    "X_val = vectorizer.transform(X_val_text) \n",
    "X_test = vectorizer.transform(X_test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialise Random Forest\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=0) \n",
    "\n",
    "# train model\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.93      6361\n",
      "           1       0.95      0.92      0.94      6659\n",
      "\n",
      "    accuracy                           0.93     13020\n",
      "   macro avg       0.93      0.94      0.93     13020\n",
      "weighted avg       0.94      0.93      0.93     13020\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_val_pred = clf.predict(X_val)\n",
    "print(classification_report(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.94      6361\n",
      "           1       0.95      0.93      0.94      6660\n",
      "\n",
      "    accuracy                           0.94     13021\n",
      "   macro avg       0.94      0.94      0.94     13021\n",
      "weighted avg       0.94      0.94      0.94     13021\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6158</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2369</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1683</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4610</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11092</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4177</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10912</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7637</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7443</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7685</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Actual  Predicted\n",
       "6158        0          0\n",
       "2369        1          1\n",
       "1683        0          1\n",
       "4610        0          0\n",
       "11092       1          1\n",
       "4177        1          1\n",
       "10912       0          0\n",
       "7637        1          1\n",
       "7443        0          0\n",
       "7685        1          1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get predictions and compare results\n",
    "predictions = clf.predict(X_test)\n",
    "results = pd.DataFrame({'Actual': y_test, 'Predicted': predictions})\n",
    "results.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9398663697104677\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "accuracy = accuracy_score(y_test,predictions)\n",
    "print(\"Accuracy:\",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9467842481374487\n",
      "Recall: 0.934984984984985\n",
      "F-measure: 0.940847624084007\n"
     ]
    }
   ],
   "source": [
    "# Precision and Recall\n",
    "precision = metrics.precision_score(y_test, predictions)\n",
    "recall = metrics.recall_score(y_test, predictions)\n",
    "f_measure = metrics.f1_score(y_test, predictions)\n",
    "print(\"Precision:\",precision)\n",
    "print(\"Recall:\",recall)\n",
    "print(\"F-measure:\",f_measure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Tf-Idf and Unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with unigram\n",
      "Testing using validation data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.93      6361\n",
      "           1       0.94      0.93      0.94      6659\n",
      "\n",
      "    accuracy                           0.94     13020\n",
      "   macro avg       0.93      0.94      0.93     13020\n",
      "weighted avg       0.94      0.94      0.94     13020\n",
      "\n",
      "------------------------------------------\n",
      "Testing using test data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94      6361\n",
      "           1       0.94      0.94      0.94      6660\n",
      "\n",
      "    accuracy                           0.94     13021\n",
      "   macro avg       0.94      0.94      0.94     13021\n",
      "weighted avg       0.94      0.94      0.94     13021\n",
      "\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "Model with unigram and bigram\n",
      "Testing using validation data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93      6361\n",
      "           1       0.94      0.94      0.94      6659\n",
      "\n",
      "    accuracy                           0.94     13020\n",
      "   macro avg       0.94      0.94      0.94     13020\n",
      "weighted avg       0.94      0.94      0.94     13020\n",
      "\n",
      "------------------------------------------\n",
      "Testing using test data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.93      6361\n",
      "           1       0.94      0.94      0.94      6660\n",
      "\n",
      "    accuracy                           0.94     13021\n",
      "   macro avg       0.94      0.94      0.94     13021\n",
      "weighted avg       0.94      0.94      0.94     13021\n",
      "\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "Model with bigram\n",
      "Testing using validation data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94      6361\n",
      "           1       0.96      0.92      0.94      6659\n",
      "\n",
      "    accuracy                           0.94     13020\n",
      "   macro avg       0.94      0.94      0.94     13020\n",
      "weighted avg       0.94      0.94      0.94     13020\n",
      "\n",
      "------------------------------------------\n",
      "Testing using test data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.94      6361\n",
      "           1       0.96      0.93      0.94      6660\n",
      "\n",
      "    accuracy                           0.94     13021\n",
      "   macro avg       0.94      0.94      0.94     13021\n",
      "weighted avg       0.94      0.94      0.94     13021\n",
      "\n",
      "------------------------------------------\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "tfidf_params = {'unigram':(1,1), 'unigram and bigram': (1,2), 'bigram':(2,2)}\n",
    "\n",
    "for ngram, values in tfidf_params.items():\n",
    "    tfidf_vectorizer = TfidfVectorizer(analyzer='word', stop_words='english', ngram_range=values)\n",
    "    tfidf_vectorizer.fit(X_train_text)\n",
    "\n",
    "    X_train = tfidf_vectorizer.transform(X_train_text)\n",
    "    X_val = tfidf_vectorizer.transform(X_val_text)\n",
    "    X_test = tfidf_vectorizer.transform(X_test_text)\n",
    "\n",
    "    print(f\"Model with {ngram}\")\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Validation Data\n",
    "    print(\"Testing using validation data:\")    \n",
    "    y_val_pred = clf.predict(X_val)\n",
    "    print(classification_report(y_val, y_val_pred))\n",
    "    print(\"------------------------------------------\")\n",
    "\n",
    "    # Test Data\n",
    "    print(\"Testing using test data:\")\n",
    "    y_test_pred = clf.predict(X_test)\n",
    "    print(classification_report(y_test, y_test_pred))\n",
    "    print(\"------------------------------------------\")\n",
    "    print(\"------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
