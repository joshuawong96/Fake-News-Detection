{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "\n",
    "# Packages for NLP\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import regex as re\n",
    "\n",
    "# Packages for sentiment analysis\n",
    "from textblob import TextBlob\n",
    "\n",
    "# Packages for visualisation \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"../Data/Combined data/train_data.csv\", index_col=0)\n",
    "val_data = pd.read_csv(\"../Data/Combined data/val_data.csv\", index_col=0)\n",
    "test_data = pd.read_csv(\"../Data/Combined data/test_data.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature ceation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating functions to get various features\n",
    "\n",
    "def get_pos_tags(text): # POS tags reference: https://www.learntek.org/blog/categorizing-pos-tagging-nltk-python/ \n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    pos_tags = nltk.pos_tag(tokens)\n",
    "    return pos_tags\n",
    "\n",
    "def get_num_nouns(text):\n",
    "    nouns_list = ['NN', 'NNS', 'NNP', 'NNPS']\n",
    "    pos_tags = get_pos_tags(text)\n",
    "    nouns_count = len([word for (word, pos) in pos_tags if pos in nouns_list])\n",
    "    return nouns_count\n",
    "\n",
    "def get_num_verbs(text):\n",
    "    verbs_list = ['VB', 'VBD', 'VBG', 'VBN', 'VDP', 'VBZ']\n",
    "    pos_tags = get_pos_tags(text)\n",
    "    verbs_count = len([word for (word, pos) in pos_tags if pos in verbs_list])\n",
    "    return verbs_count\n",
    "\n",
    "def get_num_adj(text):\n",
    "    adj_list = ['JJ', 'JJR', 'JJS']\n",
    "    pos_tags = get_pos_tags(text)\n",
    "    adj_count = len([word for (word, pos) in pos_tags if pos in adj_list])\n",
    "    return adj_count\n",
    "\n",
    "def get_num_discourse(text):\n",
    "    discourse_keywords = ['even then', 'as though', 'still', 'whereas', 'on the other hand', 'but', 'while', 'ultimately', 'if', 'even when', 'instead', 'next', 'when', 'on the one hand indeed', 'even still', 'in the end', 'meanwhile', 'separately', 'or', 'nonetheless', 'neither', 'in contrast', 'nevertheless', 'although', 'then', 'in turn', 'regardless', 'as much as', 'rather', 'meantime', 'much as', 'yet', 'however', 'even as', 'conversely', 'even after', 'nor', 'finally', 'as if', 'in fact', 'also', 'even if', 'by comparison', 'and', 'besides', 'by contrast', 'on the contrary', 'even though', 'though']\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    discourse_count = len([word for word in tokens if word in discourse_keywords])\n",
    "    return discourse_count\n",
    "\n",
    "def get_num_stopwords(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    stopword_count = len([word for word in tokens if word in stopwords.words('english')])\n",
    "    return stopword_count\n",
    "\n",
    "def get_num_punctuations(text):\n",
    "    punctuations = '!\"#$%&\\'()*+,-./:;<=>?@[\\]^_`{|}~'\n",
    "    punctuation_count = len([char for char in text if char in punctuations])\n",
    "    return punctuation_count\n",
    "\n",
    "def get_num_words_in_quotes(text):\n",
    "    quotes = re.findall(\"'.'|\\\".\\\"\", text)\n",
    "    quote_count = 0\n",
    "    if quotes is None:\n",
    "        return 0\n",
    "    else:\n",
    "        for quote in quotes:\n",
    "            words_in_quote = quote[1:-1]\n",
    "            quote_count += len(words_in_quote.split())\n",
    "        return quote_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(dataframe):\n",
    "    \"\"\"\n",
    "        Adds 13 additional features to an input dataframe and returns the updated dataframe\n",
    "    \"\"\"\n",
    "    num_nouns = []\n",
    "    num_verbs = []\n",
    "    num_adj = []\n",
    "    num_discourse = []\n",
    "    num_stopwords = []\n",
    "    num_punctuations = []\n",
    "    num_quote_words = []\n",
    "\n",
    "    for row in dataframe['text']:\n",
    "        nouns_count = get_num_nouns(row)\n",
    "        num_nouns.append(nouns_count)\n",
    "\n",
    "        verbs_count = get_num_verbs(row)\n",
    "        num_verbs.append(verbs_count)\n",
    "        \n",
    "        adj_count = get_num_adj(row)\n",
    "        num_adj.append(adj_count)\n",
    "        \n",
    "        discourse_count = get_num_discourse(row)\n",
    "        num_discourse.append(discourse_count)\n",
    "\n",
    "        stopword_count = get_num_stopwords(row)\n",
    "        num_stopwords.append(stopword_count)\n",
    "\n",
    "        punctuation_count = get_num_punctuations(row)\n",
    "        num_punctuations.append(punctuation_count)\n",
    "\n",
    "        quote_count = get_num_words_in_quotes(row)\n",
    "        num_quote_words.append(quote_count)\n",
    "    \n",
    "    dataframe['char_count'] = dataframe['text'].apply(lambda x: len(str(x)))\n",
    "    dataframe['word_count'] = dataframe['text'].apply(lambda x: len(str(x).split(\" \")))\n",
    "    dataframe['sentence_count'] = dataframe['text'].apply(lambda x: len(str(x).split(\".\")))\n",
    "    dataframe[\"num_unique_words\"] = dataframe['text'].apply(lambda x: len(set(str(x).split(\" \"))))\n",
    "    dataframe[\"avg_sentence_length\"] = dataframe['word_count']/dataframe['sentence_count']\n",
    "    dataframe['num_punctuations'] = num_punctuations\n",
    "    dataframe['num_stopwords'] = num_stopwords\n",
    "    dataframe['num_words_in_quotes'] = num_quote_words\n",
    "    dataframe['num_nouns'] = num_nouns\n",
    "    dataframe['num_verbs'] = num_verbs\n",
    "    dataframe['num_adjectives'] = num_adj\n",
    "    dataframe['num_discourse_relations'] = num_discourse\n",
    "    dataframe['textblob_sentiment'] = dataframe['text'].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
    "\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running create_features and output a new csv\n",
    "\n",
    "train_data = create_features(train_data)\n",
    "train_data.to_csv(\"../Data/Data with added features/train_data_with_added_features.csv\")\n",
    "\n",
    "test_data = create_features(test_data)\n",
    "test_data.to_csv(\"../Data/Data with added features/test_data_with_added_features.csv\")\n",
    "\n",
    "train_data = create_features(train_data)\n",
    "train_data.to_csv(\"../Data/Data with added features/train_data_with_added_features.csv\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "729bae39908f34aae3ae4cd67793570f1853d7623135d20860991de8be7ba981"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('tensorflow': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
